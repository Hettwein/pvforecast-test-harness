{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import TensorBoard, History\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from evaluation import *\n",
    "from machineLearningModel import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(13)\n",
    "\n",
    "## net params\n",
    "num_layers = 3#6\n",
    "num_neurons = 300#500\n",
    "batch_size = 100#500#1000\n",
    "dropout_rate = 0\n",
    "#const_features = ['latitude', 'longitude', 'altitude', 'modules_per_string', 'strings_per_inverter', 'tilt',\n",
    "#                  'azimuth', 'albedo', 'Technology', 'BIPV', 'A_c', 'N_s', 'pdc0', 'gamma_pdc', 'SystemID']#15\n",
    "#dyn_features = ['Wind Direction_x', 'Wind Direction_y', 'Total Cloud Cover', 'Low Cloud Cover', 'Medium Cloud Cover',\n",
    "#                'High Cloud Cover', 'Wind Speed', 'Wind Gust', 'Total Precipitation',\n",
    "#                'Snow Fraction', 'Mean Sea Level Pressure', 'DIF - backwards', 'DNI - backwards', 'Shortwave Radiation',\n",
    "#                'Temperature', 'Relative Humidity', 'Hour_x', 'Hour_y', 'Month_x', 'Month_y']#20\n",
    "const_features = ['SystemID']\n",
    "dyn_features = ['DIF - backwards', 'DNI - backwards', 'Shortwave Radiation', 'Temperature', 'Relative Humidity', 'Hour_x', 'Hour_y', 'Month_x', 'Month_y']\n",
    "target_features = ['power']\n",
    "drop_features = ['power_pvlib']\n",
    "act_fct = 'relu'\n",
    "out_act = 'linear'\n",
    "loss_fct = 'mae'\n",
    "optim = 'adam'\n",
    "metrics = []\n",
    "history = History()\n",
    "val_history = History()\n",
    "\n",
    "## data params\n",
    "filename = './data/full_data_5_systems.csv'\n",
    "correlations = ['pearson']#'pearson', 'spearman', 'kendall']\n",
    "timesteps = 5#24\n",
    "shape = (len(const_features) + len(dyn_features) + timesteps * (len(dyn_features) + len(target_features)),)# - 1\n",
    "\n",
    "## training params\n",
    "tensorboard = False\n",
    "shuffle = True\n",
    "epochs = 5#20\n",
    "val_split = 1.0/10.0\n",
    "forecast_horizon = 24\n",
    "sliding_window = 24#168#24\n",
    "dir = './test_results/'\n",
    "if not os.path.exists(dir):\n",
    "    os.makedirs(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pfname = dir + 'preprocessed_data_t-'+str(timesteps)+'_f'+str(shape[0])+'.csv'\n",
    "print(pfname)\n",
    "prep = Path(pfname)\n",
    "if prep.exists():\n",
    "    print('Loading preprocessed dataset ...')\n",
    "    pvlib = np.array_split(pd.read_csv(filename, skipinitialspace=True).set_index('time'), 5)[-1].power_pvlib\n",
    "    dataset = pd.read_csv(pfname, skipinitialspace=True).set_index(['time', 'SystemID'])\n",
    "else:\n",
    "    print('Data preprocessing ...')\n",
    "    df = pd.read_csv(filename, skipinitialspace=True).set_index('time')\n",
    "    df = np.array_split(df, 5)[-1] ##################################\n",
    "    pvlib = df.power_pvlib\n",
    "    dataset = df[const_features + dyn_features + target_features].copy()[:'2017-02-09 10:00:00']\n",
    "\n",
    "    #separate system\n",
    "    for i in range(1, timesteps + 1):\n",
    "        for feature in dyn_features + target_features:\n",
    "            sys.stdout.write(\"Shifting %i/%i %s                \\r\" % (i, timesteps, feature))\n",
    "            sys.stdout.flush()\n",
    "            dataset[feature + ' t-' + str(i)] = dataset.shift(i)[feature]\n",
    "    print('Shifting done.                ')\n",
    "\n",
    "    dataset['forecast_horizon'] = 0\n",
    "    p = dataset[target_features]\n",
    "    dataset = dataset.drop(target_features, axis=1)\n",
    "    for f in target_features:\n",
    "        dataset[f] = p[f]\n",
    "    dataset = dataset.dropna().reset_index().set_index(['time', 'SystemID'])\n",
    "\n",
    "    sys.stdout.write(\"Writing to file ...\\r\")\n",
    "    sys.stdout.flush()\n",
    "    dataset.to_csv(pfname, encoding='utf-8')\n",
    "    print('Writing done.                ')\n",
    "\n",
    "    if correlations:\n",
    "        sys.stdout.write('Computing correlations ...\\r')\n",
    "        sys.stdout.flush()\n",
    "        for corr in correlations:\n",
    "            sys.stdout.write(\"Computing %s correlation matrix                \\r\" % (corr))\n",
    "            sys.stdout.flush()\n",
    "            dataset.corr(method=corr).to_csv(dir + corr + '_correlations.csv', encoding='utf-8')\n",
    "        print('Correlations done.                   ')\n",
    "\n",
    "train, test = dataset[:('2015-10-12 06:00:00', 4.0)], dataset[('2015-10-12 07:00:00', 4.0):]\n",
    "trainX, trainY = train.iloc[:,:-len(target_features)], train.iloc[:,-len(target_features):]\n",
    "testX, testY = test.iloc[:,:-len(target_features)], test.iloc[:,-len(target_features):]\n",
    "idx = testX.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tensorboard:\n",
    "    print('tensorboard activated')\n",
    "    callbacks = [TensorBoard(log_dir='./tensorboard', histogram_freq=1, batch_size=batch_size, write_graph=True, write_grads=True, write_images=False), history]\n",
    "else:\n",
    "    callbacks = [history]\n",
    "\n",
    "#model = SARIMAX((0,1,2), (1,0,0,24))\n",
    "model = MultiLayerPerceptron(shape, len(target_features), num_layers, num_neurons, loss_fct, optim,\n",
    "                 act_fct, out_act, metrics, dropout_rate, dir + 'model.png', batch_size,\n",
    "                 epochs, val_split, callbacks, 1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = trainX\n",
    "y = trainY\n",
    "if shuffle:\n",
    "    df = pd.DataFrame(np.concatenate((trainX, trainY), axis=1))\n",
    "    df = df.sample(frac=1).values\n",
    "    y = df[:, -len(target_features):]\n",
    "    X = df[:, :-len(target_features)]\n",
    "\n",
    "model.learn(X, y)\n",
    "\n",
    "name = './saved_models/pretrained_t-'+str(timesteps)+'_f'+str(shape[0])+'_e'+str(epochs)+'_b'+str(batch_size)+'_sys'+str(4)\n",
    "# serialize model to JSON\n",
    "model_json = model.model.to_json()\n",
    "with open(name + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.model.save_weights(name + \".h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk-Forward Validation\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "method = 'pvlib'\n",
    "\n",
    "model.epochs = 5\n",
    "model.validation_split = 0.0\n",
    "model.batch_size = sliding_window\n",
    "model.verbose = 0\n",
    "\n",
    "#predictions = []\n",
    "#for i in range(len(testX)):\n",
    "#    sys.stdout.write(\"Walk-Forward Validation %i/%i\\r\" % (i+1, len(testX)))\n",
    "#    sys.stdout.flush()\n",
    "#    predictions.append(pd.DataFrame(model.forecast(testX.iloc[i:i+1,:])))\n",
    "#    window = i - sliding_window\n",
    "#    if window < 0:\n",
    "#        window = 0\n",
    "#    model.callbacks = [val_history]\n",
    "#    model.learn(testX.iloc[window:i+1,:], testY.iloc[window:i+1,:])\n",
    "#prediction = pd.concat(predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "forecast_horizon = 3\n",
    "predictions = []\n",
    "length = len(testX) - forecast_horizon - 1     #-11000\n",
    "for i in range(length):# - 10\n",
    "    sys.stdout.write(\"Walk-Forward Validation %i/%i\\r\" % (i+1, length))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # initialize values for lagged power columns\n",
    "    p = []\n",
    "    for l in range(1, timesteps + 1):\n",
    "        p.append(testX.iloc[i:i+1,:]['power t-'+str(l)].values[0])\n",
    "        \n",
    "    ps = []\n",
    "    for f in range(forecast_horizon):\n",
    "        # build input vector for future timestep\n",
    "        t = testX.iloc[i+f:i+1+f,:].copy()\n",
    "        for l in range(timesteps-1, 1, -1):\n",
    "            t['power t-' + str(l+1)] = p[l]\n",
    "            p[l] = p[l-1]\n",
    "        t['power t-1'] = p[0]\n",
    "        \n",
    "        # make prediction for input new vector\n",
    "        p[0] = model.forecast(t).item(0)\n",
    "        ps.append(p[0])\n",
    "    predictions.append(pd.DataFrame(ps))\n",
    "    \n",
    "    # train with newly available data\n",
    "    window = i - sliding_window\n",
    "    if window < 0:\n",
    "        window = 0\n",
    "    model.callbacks = [val_history]\n",
    "    model.learn(testX.iloc[window:i+1,:], testY.iloc[window:i+1,:])\n",
    "prediction = pd.concat(predictions)\n",
    "\n",
    "#name = './saved_models/trained_t-'+str(timesteps)+'_f'+str(shape[0])+'_e'+str(epochs)+'_b'+str(batch_size)+'_sys'+str(4)\n",
    "# serialize model to JSON\n",
    "#model_json = model.model.to_json()\n",
    "#with open(name + \".json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "#model.model.save_weights(name + \".h5\")\n",
    "#print(\"\\nSaved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(prediction)\n",
    "#prediction = prediction_list[:][0][1]\n",
    "#for i in range(forecast_horizon):\n",
    "#    print(prediction[:][0][i])\n",
    "a = np.empty(1)\n",
    "a.fill(np.nan)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for i in range(forecast_horizon):\n",
    "    a = np.empty(i)\n",
    "    a.fill(np.nan)\n",
    "    b = np.empty(forecast_horizon - i - 1)\n",
    "    b.fill(np.nan)\n",
    "    data['+'+str(i+1)+'h-prediction'] = np.append(np.append(a, prediction[:][0][i].values), b)#data[('prediction', 4.0)]\n",
    "\n",
    "#data['prediction'] = pd.DataFrame(np.array(prediction).reshape([len(prediction), len(target_features)])).iloc[:,0]\n",
    "data['measured'] = pd.DataFrame(np.array(testY).reshape([len(testY), len(target_features)])).iloc[:,0]\n",
    "data = data.set_index(pd.MultiIndex.from_tuples(idx[:-2])).unstack()#[:-4]\n",
    "data['pvlib'] = pvlib['2015-10-12 07:00:00':'2017-02-09 10:00:00'].reindex(data.index)\n",
    "\n",
    "tmp = pd.DataFrame()\n",
    "tmp[method] = data[method]\n",
    "tmp['measured'] = data[('measured', 4.0)]\n",
    "for i in range(forecast_horizon):\n",
    "    tmp['+'+str(i+1)+'h-prediction'] = data['+'+str(i+1)+'h-prediction']\n",
    "data = tmp\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data = data.dropna()\n",
    "#print(data)\n",
    "\n",
    "m_col = data['measured']\n",
    "l_col = data[method].dropna()\n",
    "\n",
    "for horizon in range(1, forecast_horizon + 1):\n",
    "    name = '+' + str(horizon) + 'h-prediction'\n",
    "    p_col = data[name]\n",
    "\n",
    "    walkForwardDailyLoss(m_col, p_col, l_col, method, name)\n",
    "    scatter_predictions(m_col, p_col, name)\n",
    "\n",
    "    print('%s test RMSE: %.3f' % (name, math.sqrt(mean_squared_error(m_col, p_col))))\n",
    "    print('%s test RMSE: %.3f' % (method + ' forecast', math.sqrt(mean_squared_error(m_col, l_col))))\n",
    "    draw_boxplot(m_col, p_col, l_col, method, name)\n",
    "    draw_boxplot_monthly(m_col, p_col, l_col, method, name)\n",
    "\n",
    "    m1, m2 = '2016-07-17 00:00:00', '2016-07-17 23:00:00'\n",
    "    print('%s nice day RMSE: %.3f' % (name, math.sqrt(mean_squared_error(m_col[m1:m2], p_col[m1:m2]))))\n",
    "    print('%s nice day RMSE: %.3f' % (method + ' forecast', math.sqrt(mean_squared_error(m_col[m1:m2], l_col[m1:m2]))))\n",
    "    draw_boxplot(m_col, p_col, l_col, method, name, m1, m2)\n",
    "\n",
    "    plot_timeseries(m_col, p_col, l_col, method, name, end='2015-10-19 07:00:00')\n",
    "    plot_timeseries(m_col, p_col, l_col, method, name, start='2017-02-02 10:00:00')\n",
    "    plot_timeseries(m_col, p_col, l_col, method, name, start=m1, end=m2)\n",
    "    plot_timeseries(m_col, p_col, l_col, method, name)\n",
    "    plot_timeseries(m_col, p_col, None, method, name)\n",
    "\n",
    "    draw_histogram(p_col, m_col, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_history(history)\n",
    "draw_history(val_history, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.describe())\n",
    "print(data.corr(method='pearson'))\n",
    "print(data.corr(method='spearman'))\n",
    "print(data.corr(method='kendall'))\n",
    "data.to_csv(dir + 'predictions.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    forcast_horizon = 3\n",
    "    timesteps = 5\n",
    "    testX = pd.DataFrame()\n",
    "    testY = pd.DataFrame()\n",
    "    testX['power t-5'] = [-4,-3,-2,-1,0,1,2,3,4,5]\n",
    "    testX['power t-4'] = [-3,-2,-1,0,1,2,3,4,5,6]\n",
    "    testX['power t-3'] = [-2,-1,0,1,2,3,4,5,6,7]\n",
    "    testX['power t-2'] = [-1,0,1,2,3,4,5,6,7,8]\n",
    "    testX['power t-1'] = [0,1,2,3,4,5,6,7,8,9]\n",
    "    testX['test'] = [0,1,2,3,4,5,6,7,8,9]\n",
    "    testY['power'] = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "    predictions = []\n",
    "    for i in range(len(testX)):\n",
    "        p = []\n",
    "        for l in range(1, timesteps + 1):\n",
    "            p.append(testX.iloc[i:i+1,:]['power t-'+str(l)].values[0])\n",
    "        ps = []\n",
    "        for f in range(forcast_horizon):\n",
    "            t = testX.iloc[i+f:i+1+f,:].copy()\n",
    "            for l in range(timesteps-1, 1, -1):\n",
    "                t['power t-' + str(l+1)] = p[l]\n",
    "                p[l] = p[l-1]\n",
    "            p[0] = p[0] + 1.1\n",
    "            ps.append(p[0])\n",
    "        predictions.append(ps)\n",
    "    print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
