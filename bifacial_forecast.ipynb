{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import TensorBoard, History, EarlyStopping\n",
    "from keras.layers import Input, Dense, Dropout, LeakyReLU, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model, Sequential\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output directory set to ./test_results_bifacial/\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(13)\n",
    "\n",
    "## net params\n",
    "num_layers = 5\n",
    "num_neurons = 10\n",
    "kernel_size = 2\n",
    "filter_size = 32\n",
    "act_fct = 'relu'\n",
    "out_act = 'linear'\n",
    "loss_fct = 'mae'\n",
    "optim = 'adam'\n",
    "metrics = []\n",
    "history = History()\n",
    "tilt_angles = [0, 10, 15, 18, 21, 25, 30, 35, 40, 45, 60, 90]\n",
    "features = ['GHI', 'DHI', 'BHI', 'Tamb', 'POA_ISE', 'Rain', 'Tilt Angle', 'Ws', 'Wd']# time?\n",
    "target = ['Pmpp']\n",
    "timesteps = 12\n",
    "shape = (timesteps + 1, len(features + target) + 1)\n",
    "#shape = ((len(features) + len(target)) * (timesteps + 1) - len(target),)\n",
    "\n",
    "data_dir = './data/bifacial Oct2017-Oct2018/'\n",
    "dir_ = './test_results_bifacial/'\n",
    "set_dir(dir_)\n",
    "\n",
    "## training params\n",
    "tensorboard = False\n",
    "callbacks = [EarlyStopping(patience=7, restore_best_weights=True)]\n",
    "shuffle = True\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "val_split = 1.0/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#dfs = list()\n",
    "#for tilt in tilt_angles:\n",
    "#    df = pd.read_csv(data_dir + str(tilt) + '.csv', skipinitialspace=True, sep=';').set_index('TimeStamp')\n",
    "#    df = df[target + features]\n",
    "#    df['Tilt'] = df['Tilt Angle']\n",
    "\n",
    "    # delete erroneous values\n",
    "#    df = df.drop(df['2018-09-12 10:00:00':'2018-09-17 09:00:00'].index)###################\n",
    "    \n",
    "#    for i in range(1, timesteps + 1):\n",
    "#        for feature in target + features:\n",
    "#            df[feature + ' t-' + str(i)] = df.shift(i)[feature]\n",
    "#       \n",
    "#    dfs.append(df.dropna().reset_index().set_index(['TimeStamp', 'Tilt']))\n",
    "\n",
    "#dataset = pd.concat(dfs).sort_index()\n",
    "\n",
    "#train, test = dataset[:('2018-08-16 11:00:00', 0.0)], dataset[('2018-08-16 12:00:00', 0.0):('2018-10-31 16:00:00', 90.0)]\n",
    "#trainX, trainY = train.iloc[:,len(target):], train.iloc[:,:len(target)]\n",
    "#testX, testY = test.iloc[:,len(target):], test.iloc[:,:len(target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed dataset ...\n",
      "Preprocessing done.\n"
     ]
    }
   ],
   "source": [
    "fname = dir_ + 'data_step' + str(timesteps)\n",
    "\n",
    "if Path(fname + '.npz').exists():\n",
    "    print('Loading preprocessed dataset ...')\n",
    "    with np.load(fname + '.npz') as datafile:\n",
    "        trainX = datafile['trainX']\n",
    "        trainY = datafile['trainY']\n",
    "        testX = datafile['testX']\n",
    "        testY = datafile['testY']\n",
    "        idx = datafile['idx']\n",
    "else:\n",
    "    print('Data preprocessing ...')\n",
    "    trainXs = []\n",
    "    trainYs = []\n",
    "    testXs = []\n",
    "    testYs = []\n",
    "    idxs = []\n",
    "    \n",
    "    dfs = list()\n",
    "    for tilt in tilt_angles:\n",
    "        df = pd.read_csv(data_dir + str(tilt) + '.csv', skipinitialspace=True, sep=';').set_index('TimeStamp')\n",
    "        df = df[target + features]\n",
    "        df['Tilt'] = df['Tilt Angle']\n",
    "\n",
    "        # delete erroneous values\n",
    "        df = df.drop(df['2018-09-12 10:00:00':'2018-09-17 09:00:00'].index)\n",
    "        df['forecast_horizon'] = 0\n",
    "        df = df[features + ['Tilt', 'forecast_horizon'] + target].dropna().reset_index().set_index(['TimeStamp', 'Tilt'])\n",
    "        \n",
    "        x = []\n",
    "        for i in range(timesteps+1, len(df)+1):\n",
    "            #sys.stdout.write(\"System %i/%i: %5i/%i                \\r\" % (s+1, num_sys, i, len(dataset)))\n",
    "            #sys.stdout.flush()\n",
    "            d = df.iloc[i-timesteps-1:i].copy()\n",
    "            d.iloc[-1, -len(target):] = -1\n",
    "            x.append(d.values)\n",
    "        x = np.array(x)\n",
    "        y = df[target].iloc[timesteps:]\n",
    "        \n",
    "        split = df[:'2018-09-29 07:00:00'].iloc[timesteps+1:].shape[0]\n",
    "        trainX, testX = x[:split], x[split:]\n",
    "        trainY, testY = y.iloc[:split].values, y.iloc[split:].values\n",
    "        idx = y.iloc[split:].index\n",
    "\n",
    "        trainXs.append(trainX)\n",
    "        trainYs.append(trainY)\n",
    "        testXs.append(testX)\n",
    "        testYs.append(testY)\n",
    "        idxs.append(idx)\n",
    "\n",
    "    a = np.stack(trainYs, axis=1)\n",
    "    trainY = a.reshape(a.shape[0]*a.shape[1], a.shape[2])\n",
    "\n",
    "    a = np.stack(trainXs, axis=1)\n",
    "    trainX = a.reshape(a.shape[0]*a.shape[1], a.shape[2], a.shape[3])\n",
    "\n",
    "    a = np.stack(testYs, axis=1)\n",
    "    testY = a.reshape(a.shape[0]*a.shape[1], a.shape[2])\n",
    "\n",
    "    a = np.stack(testXs, axis=1)\n",
    "    testX = a.reshape(a.shape[0]*a.shape[1], a.shape[2], a.shape[3])\n",
    "\n",
    "    a = np.stack(idxs, axis=1)\n",
    "    idx = a.reshape(a.shape[0]*a.shape[1])\n",
    "\n",
    "    np.savez(fname, trainX=trainX, trainY=trainY, testX=testX, testY=testY, idx=idx)\n",
    "    print('Saved to ' + fname + '.npz       ')\n",
    "print('Preprocessing done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filter_size, kernel_size, input_shape=shape, activation=act_fct, dilation_rate=1, padding='causal', kernel_initializer='he_uniform'))\n",
    "for n in range(num_layers):\n",
    "    model.add(Conv1D(filter_size, kernel_size, activation=act_fct, dilation_rate=2**(n+1), padding='causal', kernel_initializer='he_uniform'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_neurons, activation=act_fct, kernel_initializer='he_uniform'))\n",
    "model.add(Dense(num_neurons, activation=act_fct, kernel_initializer='he_uniform'))\n",
    "model.add(Dense(num_neurons, activation=act_fct, kernel_initializer='he_uniform'))\n",
    "model.add(Dense(len(target)))\n",
    "model.add(LeakyReLU(alpha=0.001))\n",
    "model.compile(loss=loss_fct, optimizer=optim, metrics=metrics)\n",
    "\n",
    "\n",
    "#visible = Input(shape=shape)\n",
    "#dense = visible\n",
    "#for layer in range(0, num_layers):\n",
    "#    dense = Dense(num_neurons, activation=act_fct)(dense)\n",
    "#output = Dense(len(target), activation=out_act)(dense)\n",
    "#model = Model(inputs=visible, outputs=output)\n",
    "#model.compile(loss=loss_fct, optimizer=optim, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28177 samples, validate on 3131 samples\n",
      "Epoch 1/100\n",
      "28177/28177 [==============================] - 12s 412us/step - loss: 18.4325 - val_loss: 7.0246\n",
      "Epoch 2/100\n",
      "28177/28177 [==============================] - 9s 309us/step - loss: 6.2998 - val_loss: 7.5977\n",
      "Epoch 3/100\n",
      "28177/28177 [==============================] - 8s 288us/step - loss: 5.0387 - val_loss: 4.1704\n",
      "Epoch 4/100\n",
      "28177/28177 [==============================] - 9s 306us/step - loss: 4.7526 - val_loss: 4.0844\n",
      "Epoch 5/100\n",
      "28177/28177 [==============================] - 9s 320us/step - loss: 4.1307 - val_loss: 3.8513\n",
      "Epoch 6/100\n",
      "28177/28177 [==============================] - 9s 308us/step - loss: 4.1896 - val_loss: 4.6103\n",
      "Epoch 7/100\n",
      "28177/28177 [==============================] - 9s 320us/step - loss: 3.7930 - val_loss: 5.3584\n",
      "Epoch 8/100\n",
      "28177/28177 [==============================] - 9s 309us/step - loss: 3.5433 - val_loss: 3.3174\n",
      "Epoch 9/100\n",
      "28177/28177 [==============================] - 9s 324us/step - loss: 3.7434 - val_loss: 4.0052\n",
      "Epoch 10/100\n",
      "28177/28177 [==============================] - 9s 323us/step - loss: 3.5013 - val_loss: 5.9828\n",
      "Epoch 11/100\n",
      "28177/28177 [==============================] - 9s 329us/step - loss: 3.3776 - val_loss: 3.4622\n",
      "Epoch 12/100\n",
      "28177/28177 [==============================] - 9s 323us/step - loss: 3.3514 - val_loss: 3.3677\n",
      "Epoch 13/100\n",
      "28177/28177 [==============================] - 8s 292us/step - loss: 3.2860 - val_loss: 3.6902\n",
      "Epoch 14/100\n",
      "28177/28177 [==============================] - 10s 344us/step - loss: 3.0860 - val_loss: 3.1549\n",
      "Epoch 15/100\n",
      "28177/28177 [==============================] - 9s 303us/step - loss: 3.0380 - val_loss: 3.4850\n",
      "Epoch 16/100\n",
      "28177/28177 [==============================] - 9s 328us/step - loss: 3.1888 - val_loss: 2.7204\n",
      "Epoch 17/100\n",
      "28177/28177 [==============================] - 11s 402us/step - loss: 2.9488 - val_loss: 3.1213\n",
      "Epoch 18/100\n",
      "28177/28177 [==============================] - 12s 442us/step - loss: 2.9740 - val_loss: 3.7468\n",
      "Epoch 19/100\n",
      "28177/28177 [==============================] - 12s 437us/step - loss: 3.0388 - val_loss: 2.7116\n",
      "Epoch 20/100\n",
      "28177/28177 [==============================] - 12s 437us/step - loss: 2.9152 - val_loss: 3.3162\n",
      "Epoch 21/100\n",
      "28177/28177 [==============================] - 12s 433us/step - loss: 2.8784 - val_loss: 3.2366\n",
      "Epoch 22/100\n",
      "28177/28177 [==============================] - 11s 407us/step - loss: 2.7362 - val_loss: 2.6772\n",
      "Epoch 23/100\n",
      "28177/28177 [==============================] - 11s 402us/step - loss: 2.8789 - val_loss: 2.8868\n",
      "Epoch 24/100\n",
      "28177/28177 [==============================] - 12s 412us/step - loss: 2.6639 - val_loss: 3.4183\n",
      "Epoch 25/100\n",
      "28177/28177 [==============================] - 10s 351us/step - loss: 2.8322 - val_loss: 2.7153\n",
      "Epoch 26/100\n",
      "28177/28177 [==============================] - 9s 322us/step - loss: 2.6373 - val_loss: 3.3317\n",
      "Epoch 27/100\n",
      "28177/28177 [==============================] - 9s 317us/step - loss: 2.6899 - val_loss: 2.8286\n",
      "Epoch 28/100\n",
      "15900/28177 [===============>..............] - ETA: 4s - loss: 2.6745"
     ]
    }
   ],
   "source": [
    "callbacks = callbacks\n",
    "if tensorboard:\n",
    "    print('tensorboard activated')\n",
    "    callbacks.append(TensorBoard(log_dir='./tensorboard', histogram_freq=1, batch_size=batch_size, write_graph=True, write_grads=True, write_images=False))\n",
    "\n",
    "model.fit(trainX, trainY, batch_size, epochs=epochs, validation_split=val_split, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 0s 644us/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(testX, batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tilt Angle: 0\n",
      "\n",
      "+1h-prediction tilt=0 test RMSE: 0.745\n",
      "\n",
      "\n",
      "Tilt Angle: 10\n",
      "\n",
      "+1h-prediction tilt=10 test RMSE: 0.754\n",
      "\n",
      "\n",
      "Tilt Angle: 15\n",
      "\n",
      "+1h-prediction tilt=15 test RMSE: 0.942\n",
      "\n",
      "\n",
      "Tilt Angle: 18\n",
      "\n",
      "+1h-prediction tilt=18 test RMSE: 0.719\n",
      "\n",
      "\n",
      "Tilt Angle: 21\n",
      "\n",
      "+1h-prediction tilt=21 test RMSE: 0.746\n",
      "\n",
      "\n",
      "Tilt Angle: 25\n",
      "\n",
      "+1h-prediction tilt=25 test RMSE: 0.707\n",
      "\n",
      "\n",
      "Tilt Angle: 30\n",
      "\n",
      "+1h-prediction tilt=30 test RMSE: 0.749\n",
      "\n",
      "\n",
      "Tilt Angle: 35\n",
      "\n",
      "+1h-prediction tilt=35 test RMSE: 0.766\n",
      "\n",
      "\n",
      "Tilt Angle: 40\n",
      "\n",
      "+1h-prediction tilt=40 test RMSE: 0.759\n",
      "\n",
      "\n",
      "Tilt Angle: 45\n",
      "\n",
      "+1h-prediction tilt=45 test RMSE: 0.745\n",
      "\n",
      "\n",
      "Tilt Angle: 60\n",
      "\n",
      "+1h-prediction tilt=60 test RMSE: 0.858\n",
      "\n",
      "\n",
      "Tilt Angle: 90\n",
      "\n",
      "+1h-prediction tilt=90 test RMSE: 1.013\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "data['prediction'] = pd.DataFrame(np.array(prediction).reshape([len(prediction), len(target)])).iloc[:,0]\n",
    "data['measured'] = pd.DataFrame(np.array(testY).reshape([len(testY), len(target)])).iloc[:,0]\n",
    "data = data.set_index(pd.MultiIndex.from_tuples(idx)).unstack()\n",
    "data.index = pd.to_datetime(data.index)\n",
    "\n",
    "\n",
    "for tilt in tilt_angles:\n",
    "    print('\\n\\nTilt Angle: ' + str(tilt) + '\\n')\n",
    "    horizon = 1\n",
    "    name = '+' + str(horizon) + 'h-prediction tilt=' + str(tilt) \n",
    "    p_col = data[('prediction', tilt)]#name]\n",
    "    m_col = data[('measured', tilt)]\n",
    "\n",
    "    walkForwardDailyLoss(m_col, p_col, horizon=name)\n",
    "    scatter_predictions(m_col, p_col, name)\n",
    "\n",
    "    print('%s test RMSE: %.3f' % (name, math.sqrt(mean_squared_error(m_col, p_col))))\n",
    "    draw_boxplot(m_col, p_col, horizon=name)\n",
    "    #draw_boxplot_monthly(m_col, p_col, horizon=name)\n",
    "    #m1, m2 = '2018-08-18 10:00:00', '2018-08-18 14:00:00'\n",
    "    #print('%s nice day RMSE: %.3f' % (name, math.sqrt(mean_squared_error(m_col[m1:m2], p_col[m1:m2]))))\n",
    "    #draw_boxplot(m_col, p_col, horizon=name, start=m1, end=m2)\n",
    "\n",
    "    plot_timeseries(m_col, p_col, None, None, name, end='2018-08-22 12:00:00')\n",
    "    plot_timeseries(m_col, p_col, None, None, name, start='2018-10-25 08:00:00')\n",
    "    #plot_timeseries(m_col, p_col, None, None, name, start=m1, end=m2)\n",
    "    plot_timeseries(m_col, p_col, None, None, name)\n",
    "\n",
    "draw_histogram(p_col, m_col, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      prediction                                                         \\\n",
      "            0.0        10.0       15.0       18.0       21.0       25.0   \n",
      "count  30.000000  30.000000  30.000000  30.000000  30.000000  30.000000   \n",
      "mean   23.784891  23.622103  23.114223  23.150133  22.880228  22.599836   \n",
      "std    19.531601  19.621101  19.634401  19.433277  19.366890  19.243776   \n",
      "min     3.265229   2.884106   3.118170   3.033156   3.215443   3.150404   \n",
      "25%    12.814092  12.676464  12.627223  12.064635  12.055649  11.603865   \n",
      "50%    16.924003  16.547441  16.088140  16.254501  15.966619  15.843459   \n",
      "75%    24.707148  24.155625  23.913296  23.712176  23.308506  22.966338   \n",
      "max    75.286827  75.313782  75.092873  74.243912  74.278244  73.067940   \n",
      "\n",
      "                                                     ...       measured  \\\n",
      "            30.0       35.0       40.0       45.0    ...           15.0   \n",
      "count  30.000000  30.000000  30.000000  30.000000    ...      30.000000   \n",
      "mean   22.148108  21.728926  21.298565  20.894787    ...      23.590906   \n",
      "std    18.974510  18.747227  18.369938  18.164351    ...      20.129480   \n",
      "min     2.935868   2.843404   2.828035   2.455589    ...       3.075400   \n",
      "25%    11.658748  11.347415  11.025027  10.707539    ...      12.268629   \n",
      "50%    15.766206  15.411794  15.170496  14.684002    ...      16.163980   \n",
      "75%    22.342717  21.759383  21.271428  21.029370    ...      24.218584   \n",
      "max    72.141884  71.203506  69.925858  69.154343    ...      76.897828   \n",
      "\n",
      "                                                                         \\\n",
      "            18.0       21.0       25.0       30.0       35.0       40.0   \n",
      "count  30.000000  30.000000  30.000000  30.000000  30.000000  30.000000   \n",
      "mean   23.393050  23.188181  22.884911  22.434248  22.003203  21.552376   \n",
      "std    20.027935  19.956184  19.803894  19.568545  19.311447  19.021261   \n",
      "min     3.059600   2.992800   2.941600   2.874600   2.813000   2.708600   \n",
      "25%    12.169396  12.038580  11.851354  11.561155  11.308927  11.050351   \n",
      "50%    16.033376  15.958679  15.838470  15.587514  15.344932  14.948059   \n",
      "75%    23.912424  23.588003  23.176121  22.591773  22.044178  21.506516   \n",
      "max    76.463931  76.049034  75.275828  74.215241  73.062069  71.826517   \n",
      "\n",
      "                                        \n",
      "            45.0       60.0       90.0  \n",
      "count  30.000000  30.000000  30.000000  \n",
      "mean   21.122311  20.000930  18.091322  \n",
      "std    18.776892  18.025236  16.128128  \n",
      "min     2.661400   2.444600   2.234800  \n",
      "25%    10.794584  10.131356   9.138846  \n",
      "50%    14.586000  13.594728  12.217050  \n",
      "75%    20.936034  19.686259  17.878570  \n",
      "max    70.805621  67.881000  60.757667  \n",
      "\n",
      "[8 rows x 24 columns]\n",
      "                prediction                                                    \\\n",
      "                      0.0       10.0      15.0      18.0      21.0      25.0   \n",
      "prediction 0.0    1.000000  0.999584  0.999408  0.999271  0.999115  0.998898   \n",
      "           10.0   0.999584  1.000000  0.999467  0.999854  0.999705  0.999593   \n",
      "           15.0   0.999408  0.999467  1.000000  0.999500  0.999559  0.999301   \n",
      "           18.0   0.999271  0.999854  0.999500  1.000000  0.999889  0.999873   \n",
      "           21.0   0.999115  0.999705  0.999559  0.999889  1.000000  0.999920   \n",
      "           25.0   0.998898  0.999593  0.999301  0.999873  0.999920  1.000000   \n",
      "           30.0   0.998618  0.999554  0.999150  0.999746  0.999802  0.999820   \n",
      "           35.0   0.998352  0.999234  0.999118  0.999590  0.999739  0.999789   \n",
      "           40.0   0.997695  0.998952  0.998648  0.999436  0.999555  0.999671   \n",
      "           45.0   0.997639  0.998964  0.998511  0.999432  0.999490  0.999605   \n",
      "           60.0   0.997188  0.998502  0.998305  0.999080  0.999262  0.999422   \n",
      "           90.0   0.997839  0.999022  0.998707  0.999397  0.999487  0.999603   \n",
      "measured   0.0    0.999750  0.999413  0.999083  0.999150  0.998945  0.998748   \n",
      "           10.0   0.999633  0.999713  0.999397  0.999661  0.999541  0.999423   \n",
      "           15.0   0.999457  0.999758  0.999446  0.999808  0.999726  0.999642   \n",
      "           18.0   0.999284  0.999723  0.999431  0.999846  0.999792  0.999733   \n",
      "           21.0   0.999096  0.999670  0.999375  0.999864  0.999832  0.999811   \n",
      "           25.0   0.998882  0.999577  0.999302  0.999842  0.999838  0.999844   \n",
      "           30.0   0.998520  0.999402  0.999100  0.999749  0.999781  0.999832   \n",
      "           35.0   0.998193  0.999219  0.998931  0.999641  0.999703  0.999785   \n",
      "           40.0   0.997941  0.999055  0.998762  0.999534  0.999613  0.999724   \n",
      "           45.0   0.997715  0.998895  0.998612  0.999420  0.999526  0.999660   \n",
      "           60.0   0.997018  0.998437  0.998126  0.999049  0.999219  0.999409   \n",
      "           90.0   0.997063  0.998431  0.998103  0.999005  0.999120  0.999343   \n",
      "\n",
      "                                                           ...     measured  \\\n",
      "                     30.0      35.0      40.0      45.0    ...         15.0   \n",
      "prediction 0.0   0.998618  0.998352  0.997695  0.997639    ...     0.999457   \n",
      "           10.0  0.999554  0.999234  0.998952  0.998964    ...     0.999758   \n",
      "           15.0  0.999150  0.999118  0.998648  0.998511    ...     0.999446   \n",
      "           18.0  0.999746  0.999590  0.999436  0.999432    ...     0.999808   \n",
      "           21.0  0.999802  0.999739  0.999555  0.999490    ...     0.999726   \n",
      "           25.0  0.999820  0.999789  0.999671  0.999605    ...     0.999642   \n",
      "           30.0  1.000000  0.999708  0.999720  0.999612    ...     0.999545   \n",
      "           35.0  0.999708  1.000000  0.999802  0.999697    ...     0.999208   \n",
      "           40.0  0.999720  0.999802  1.000000  0.999872    ...     0.999014   \n",
      "           45.0  0.999612  0.999697  0.999872  1.000000    ...     0.998952   \n",
      "           60.0  0.999379  0.999689  0.999795  0.999762    ...     0.998476   \n",
      "           90.0  0.999560  0.999697  0.999735  0.999706    ...     0.998865   \n",
      "measured   0.0   0.998533  0.997987  0.997535  0.997512    ...     0.999626   \n",
      "           10.0  0.999283  0.998870  0.998586  0.998538    ...     0.999954   \n",
      "           15.0  0.999545  0.999208  0.999014  0.998952    ...     1.000000   \n",
      "           18.0  0.999660  0.999370  0.999235  0.999166    ...     0.999981   \n",
      "           21.0  0.999748  0.999509  0.999437  0.999366    ...     0.999927   \n",
      "           25.0  0.999797  0.999613  0.999592  0.999508    ...     0.999845   \n",
      "           30.0  0.999808  0.999676  0.999736  0.999657    ...     0.999682   \n",
      "           35.0  0.999780  0.999709  0.999827  0.999738    ...     0.999499   \n",
      "           40.0  0.999721  0.999686  0.999849  0.999770    ...     0.999357   \n",
      "           45.0  0.999647  0.999655  0.999852  0.999788    ...     0.999204   \n",
      "           60.0  0.999430  0.999545  0.999786  0.999748    ...     0.998724   \n",
      "           90.0  0.999402  0.999427  0.999600  0.999532    ...     0.998742   \n",
      "\n",
      "                                                                             \\\n",
      "                     18.0      21.0      25.0      30.0      35.0      40.0   \n",
      "prediction 0.0   0.999284  0.999096  0.998882  0.998520  0.998193  0.997941   \n",
      "           10.0  0.999723  0.999670  0.999577  0.999402  0.999219  0.999055   \n",
      "           15.0  0.999431  0.999375  0.999302  0.999100  0.998931  0.998762   \n",
      "           18.0  0.999846  0.999864  0.999842  0.999749  0.999641  0.999534   \n",
      "           21.0  0.999792  0.999832  0.999838  0.999781  0.999703  0.999613   \n",
      "           25.0  0.999733  0.999811  0.999844  0.999832  0.999785  0.999724   \n",
      "           30.0  0.999660  0.999748  0.999797  0.999808  0.999780  0.999721   \n",
      "           35.0  0.999370  0.999509  0.999613  0.999676  0.999709  0.999686   \n",
      "           40.0  0.999235  0.999437  0.999592  0.999736  0.999827  0.999849   \n",
      "           45.0  0.999166  0.999366  0.999508  0.999657  0.999738  0.999770   \n",
      "           60.0  0.998734  0.998988  0.999167  0.999365  0.999505  0.999564   \n",
      "           90.0  0.999071  0.999259  0.999396  0.999517  0.999600  0.999610   \n",
      "measured   0.0   0.999447  0.999234  0.999001  0.998639  0.998284  0.998037   \n",
      "           10.0  0.999882  0.999773  0.999639  0.999408  0.999167  0.998989   \n",
      "           15.0  0.999981  0.999927  0.999845  0.999682  0.999499  0.999357   \n",
      "           18.0  1.000000  0.999980  0.999930  0.999811  0.999666  0.999548   \n",
      "           21.0  0.999980  1.000000  0.999983  0.999911  0.999804  0.999711   \n",
      "           25.0  0.999930  0.999983  1.000000  0.999969  0.999899  0.999829   \n",
      "           30.0  0.999811  0.999911  0.999969  1.000000  0.999978  0.999941   \n",
      "           35.0  0.999666  0.999804  0.999899  0.999978  1.000000  0.999989   \n",
      "           40.0  0.999548  0.999711  0.999829  0.999941  0.999989  1.000000   \n",
      "           45.0  0.999414  0.999603  0.999741  0.999885  0.999957  0.999987   \n",
      "           60.0  0.998992  0.999242  0.999435  0.999660  0.999799  0.999871   \n",
      "           90.0  0.998999  0.999227  0.999406  0.999601  0.999724  0.999780   \n",
      "\n",
      "                                               \n",
      "                     45.0      60.0      90.0  \n",
      "prediction 0.0   0.997715  0.997018  0.997063  \n",
      "           10.0  0.998895  0.998437  0.998431  \n",
      "           15.0  0.998612  0.998126  0.998103  \n",
      "           18.0  0.999420  0.999049  0.999005  \n",
      "           21.0  0.999526  0.999219  0.999120  \n",
      "           25.0  0.999660  0.999409  0.999343  \n",
      "           30.0  0.999647  0.999430  0.999402  \n",
      "           35.0  0.999655  0.999545  0.999427  \n",
      "           40.0  0.999852  0.999786  0.999600  \n",
      "           45.0  0.999788  0.999748  0.999532  \n",
      "           60.0  0.999611  0.999687  0.999486  \n",
      "           90.0  0.999612  0.999575  0.999543  \n",
      "measured   0.0   0.997794  0.997048  0.997140  \n",
      "           10.0  0.998806  0.998238  0.998294  \n",
      "           15.0  0.999204  0.998724  0.998742  \n",
      "           18.0  0.999414  0.998992  0.998999  \n",
      "           21.0  0.999603  0.999242  0.999227  \n",
      "           25.0  0.999741  0.999435  0.999406  \n",
      "           30.0  0.999885  0.999660  0.999601  \n",
      "           35.0  0.999957  0.999799  0.999724  \n",
      "           40.0  0.999987  0.999871  0.999780  \n",
      "           45.0  1.000000  0.999927  0.999803  \n",
      "           60.0  0.999927  1.000000  0.999878  \n",
      "           90.0  0.999803  0.999878  1.000000  \n",
      "\n",
      "[24 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.describe())\n",
    "print(data.corr(method='pearson'))\n",
    "#data.to_csv(dir + 'predictions.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
